epoch :  9
train loss: 247721.06740925144
test loss: 244089.73388976973
r2: -51.88091589264799
epoch :  5009
train loss: 236889.8090539938
test loss: 233474.4467047555
r2: -49.581162847480826
epoch :  10009
train loss: 206702.0121788322
test loss: 203704.6170488675
r2: -43.131666454968055
epoch :  15009
train loss: 157511.43466005882
test loss: 155202.70655831447
r2: -32.623951081563845
epoch :  20009
train loss: 98741.99182622874
test loss: 96864.69828365676
r2: -19.98529045559119
epoch :  25009
train loss: 44855.58422205186
test loss: 43920.600430836894
r2: -8.51519566319224
epoch :  30009
train loss: 10428.412510476412
test loss: 10402.74632158382
r2: -1.2537070466579063
epoch :  35009
train loss: 559.374295874034
test loss: 1018.7571002104199
r2: 0.7792909694612802
epoch :  40009
train loss: 396.27320364485905
test loss: 896.4272307489332
r2: 0.8057931718893137
epoch :  45009
train loss: 367.2144500676028
test loss: 802.0377967369423
r2: 0.8262422077483835
epoch :  50009
train loss: 337.9194969976672
test loss: 747.5647200907036
r2: 0.838043548749658
epoch :  55009
train loss: 310.1595390140823
test loss: 729.607807512782
r2: 0.8419338311003018
epoch :  60009
train loss: 283.93683438422664
test loss: 720.6397981636588
r2: 0.8438767089942555
epoch :  65009
train loss: 243.69357585074516
test loss: 660.9201785423851
r2: 0.8568146893509372
epoch :  70009
train loss: 224.78578138217816
test loss: 629.0243634692997
r2: 0.8637247706858981
epoch :  75009
train loss: 213.45324490525445
test loss: 616.505664619089
r2: 0.8664368890959347
epoch :  80009
train loss: 204.51034855533624
test loss: 606.5586811970963
r2: 0.8685918572109047
